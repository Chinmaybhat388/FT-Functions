{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the field task excel sheet to extract relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_colwidth',None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Downloads/change_request_hardware_Jan_to_Nov_2020.xlsx',sheet_name=0)\n",
    "\n",
    "\n",
    "#Standard Table\n",
    "std_df = pd.read_excel(\"D:\\Data Viz\\Cluster_Details.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract the RFC number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rfc(dataframe):\n",
    "    rfc = dataframe[['Number']].copy()\n",
    "    return rfc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract the server name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(dataframe):\n",
    "    \n",
    "    #Select only the rows needed.\n",
    "    ServerName_df = dataframe[['Short description','Description','Implementation plan']]\n",
    "    \n",
    "    #Extract only relevant information and discard the rest in each column\n",
    "    for col in ServerName_df.columns:\n",
    "        ServerName_df[col] = ServerName_df[col].str.extract(r'([exEX]\\w{2,7}\\d{2})',expand=False).str.strip()\n",
    "        \n",
    "    #Replacing NaN values with 'x' so that when counting length of characters, we don't get TypeError.\n",
    "    ServerName_df = ServerName_df.fillna('x')\n",
    "    \n",
    "    #Length list will store the column with longest name for server in that row.\n",
    "    length = []\n",
    "    machine_name = []\n",
    "    \n",
    "    for row in range(ServerName_df.shape[0]):\n",
    "        for col in ServerName_df.loc[row,]:\n",
    "            length.append(len(col))\n",
    "        longest = np.argmax(length)\n",
    "        machine_name.append(ServerName_df.iloc[row,longest]) #Append the column value with the longest string to our list.\n",
    "        #Reset the length list for the next row\n",
    "        length = []\n",
    "    \n",
    "    #Convert all to lowercase\n",
    "    machine_name = map(str.lower,machine_name)        \n",
    "        \n",
    "    return pd.DataFrame(machine_name,columns = ['Machine name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract Data center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_center(dataframe):\n",
    "    Datacenter = dataframe['Implementer Group'].str.extract(r'(TPC|NJ|TN2)')\n",
    "    Datacenter = Datacenter.replace('NJ','CNJ')\n",
    "    Datacenter.columns = ['Datacenter']\n",
    "    return Datacenter    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract Date of Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(dataframe):\n",
    "    Start_time = dataframe[['Planned start date']]\n",
    "    return Start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract Faulty component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_faulty(dataframe):\n",
    "    #Define a pattern to extract. The most commonly observed failures are included to search in the text.\n",
    "    pattern = re.compile(r'(DIMM|disk|pcie|eth|processor|battery|fan module|cable|ilom|motherboard|sensor|IB switch|power supply|upgrading|PDU|PSU)',re.I)\n",
    "    \n",
    "    #str.title capitalizes first letter of each word.\n",
    "    faulty_component = dataframe['Description'].str.extract(pattern,expand=False).str.strip().str.title()\n",
    "    \n",
    "    #Replace some non standard data entries if found.\n",
    "    faulty_component = faulty_component.replace(['Upgrading','Pdu','Psu'],['Memory upgrade','Power Supply','Power Supply'])\n",
    "    faulty_component = pd.DataFrame(faulty_component)\n",
    "    faulty_component.columns = ['Faulty component']\n",
    "    \n",
    "    return faulty_component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract cluster names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cluster(dataframe):\n",
    "    \n",
    "    Machine_name = extract_name(df)\n",
    "    \n",
    "    #Pattern to extract\n",
    "    pattern = re.compile(r'(.{5})',re.I)\n",
    "    \n",
    "    cluster = Machine_name['Machine name'].str.extract(pattern,expand=False).str.strip().str.lower()\n",
    "    cluster = pd.DataFrame(cluster)\n",
    "    cluster.columns = ['Cluster']\n",
    "    \n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract Node type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_type(dataframe):\n",
    "    \n",
    "    Machine_name = extract_name(df)\n",
    "    \n",
    "    conditions = [Machine_name['Machine name'].str.contains(r'(db|DB)',regex=True),\n",
    "            Machine_name['Machine name'].str.contains(r'(cel|CEL)',regex=True),\n",
    "            Machine_name['Machine name'].str.contains(r'(ib|IB)',regex=True),\n",
    "            Machine_name['Machine name'].str.contains(r'(zfs|ZFS)',regex=True),\n",
    "            Machine_name['Machine name'].str.contains(r'(zdm|ZDM)',regex=True)]\n",
    "    \n",
    "    values = ['Database','Cell','IB-Switch','ZFS-Storage','ZDLRA-db']\n",
    "    \n",
    "    node_type = np.select(conditions,values)\n",
    "    node_type = pd.DataFrame(node_type)\n",
    "    node_type.columns = ['Node type']\n",
    "    \n",
    "    return node_type   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract Machine type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_machine_type(dataframe):\n",
    "    \n",
    "    Node_type = extract_node_type(df)\n",
    "    \n",
    "    conditions = [Node_type['Node type'].str.contains(r'^ZFS',regex=True),\n",
    "             Node_type['Node type'].str.contains(r'^ZDLRA',regex=True),\n",
    "             Node_type['Node type'].str.contains(r'^Database|^Cell|^IB',regex=True),\n",
    "             ]\n",
    "    \n",
    "    values = ['ZFS','ZDLRA','Exadata']\n",
    "    \n",
    "    machine_type = np.select(conditions,values)\n",
    "    machine_type = pd.DataFrame(machine_type)\n",
    "    machine_type.columns = ['Machine type']\n",
    "    \n",
    "    return machine_type    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract Machine version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_version(dataframe):\n",
    "    \n",
    "    version_pattern = re.compile(r'(X\\d-\\d)',re.I)\n",
    "\n",
    "    machine_version = dataframe['Description'].str.extract(version_pattern,expand=False).str.strip()\n",
    "    \n",
    "    #Fill na if other column has any version information\n",
    "    machine_version.fillna(dataframe['Description'].str.extract(version_pattern,expand=False).str.strip(),inplace = True)\n",
    "    \n",
    "    machine_version = pd.DataFrame(machine_version)\n",
    "    machine_version.columns = ['Machine version']\n",
    "    \n",
    "    return machine_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract Downtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_downtime(dataframe):\n",
    "    \n",
    "    Faulty_component = extract_faulty(df)\n",
    "    \n",
    "    downtime = np.where(Faulty_component['Faulty component'].str.contains(r'(Dimm|Processor|Ib Switch|Motherboard|Ilom|NodeDown|Battery)'),\\\n",
    "                             'Yes','No')\n",
    "    \n",
    "    downtime = pd.DataFrame(downtime)\n",
    "    downtime.columns = ['Downtime']\n",
    "    \n",
    "    return downtime\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract GF vs BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_region(dataframe):\n",
    "    \n",
    "    Machine_name = extract_name(df)\n",
    "    \n",
    "    region = np.where(Machine_name['Machine name'].str.contains(r'(xt0|xc0|xlmd|xlmc|elpd|elpc)',regex=True),'BF','GF')\n",
    "    region = pd.DataFrame(region)\n",
    "    region.columns = ['Region']\n",
    "    \n",
    "    return region\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract the missing versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to extract version from the std lookup table.\n",
    "def missing_versions(dataframe1,std_dataframe):\n",
    "    x = pd.concat([extract_cluster(dataframe1),extract_version(dataframe1)],axis = 1)\n",
    "    y = std_dataframe[['Cluster']]\n",
    "    \n",
    "    new_df = ms_df.merge(std_df,on = 'Cluster',how = 'left',indicator=True)\n",
    "    \n",
    "    new_df['Machine version_x'].fillna(new_df['Machine version_y'],inplace=True)\n",
    "    \n",
    "    mv = pd.DataFrame(new_df['Machine version_x'])\n",
    "    mv.columns = ['Machine version']\n",
    "    \n",
    "    return mv\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract Action time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_action_time(dataframe):\n",
    "    difference = (df['Planned start date'] - df['Created'])/np.timedelta64(1,'D')\n",
    "    difference = round(difference,0)\n",
    "    difference.astype(int)\n",
    "    \n",
    "    difference = pd.DataFrame(difference)\n",
    "    difference.columns = ['Action time']\n",
    "    \n",
    "    return difference\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(dataframe):\n",
    "    table = pd.concat([extract_rfc(dataframe),extract_machine_type(dataframe),extract_node_type(dataframe),\\\n",
    "                       extract_name(dataframe),extract_cluster(dataframe),missing_versions(dataframe,std_dataframe),\\\n",
    "                       extract_faulty(dataframe),extract_date(dataframe),extract_data_center(dataframe),\\\n",
    "                       extract_region(dataframe),extract_downtime(dataframe),extract_action_time(dataframe)],axis = 1)\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "final_df = create_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_excel('D:\\Data Viz\\FuncOut.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- extract_rfc\n",
    "- extract_machine_type\n",
    "- extract_node_type\n",
    "- extract_name\n",
    "- extract_cluster\n",
    "- extract_version\n",
    "- extract_faulty\n",
    "- extract_date\n",
    "- extract_data_center\n",
    "- extract_region\n",
    "- extract_downtime\n",
    "- missing_versions\n",
    "- extract_action_time\n",
    "- create_table\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
